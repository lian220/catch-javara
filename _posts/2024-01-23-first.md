---
layout: single
title:  "대량 데이터 배치 처리 및 네이버 API 연동 개선 정리"
categories:
  - spring
sidebar:
  nav: sidebar-category
---

---


# 대량 데이터 배치 처리 및 네이버 API 연동 개선 정리

아래 정리는 기존 배치 방식(Offset 기반, JPA Cursor 등)에서 성능 및 메모리 이슈를 겪던 문제를 해결하기 위해 **ZeroOffsetItemReader**, **ExposedCursorItemReader**, 그리고 **Redis 파이프라인** 등을 활용하여 대용량 처리를 개선한 내용입니다.  
추가로, **네이버 검색 API를 여러 클라이언트 키로 번갈아가며 사용**(Key 로테이션)함으로써 `429`(Too Many Requests) 에러를 회피하는 방법도 함께 적용했습니다.

---

## 1. 기존 배치(ItemReader) 문제점

1. **JpaPagingItemReader / RepositoryItemReader**  
   - `LIMIT / OFFSET` 구문을 활용하기 때문에 대량(수천만 건) 데이터를 페이징 처리할 때 **Offset 스캔 비용**이 커져 성능이 급격히 저하.
   - 뒤 페이지로 갈수록 `OFFSET n`이 커지면 응답 속도가 크게 떨어짐.

2. **JpaCursorItemReader / HibernateCursorItemReader**  
   - Cursor 방식 자체는 빠르게 데이터를 가져올 수 있으나, **애플리케이션 메모리를 많이 소모(OOM 위험)**.
   - 페치 사이즈를 조정해도 데이터가 지나치게 많으면 여전히 리소스 부담이 커질 수 있음.

3. **DB 의존적 Aggregation**  
   - 집계(Aggregation) 로직을 DB 쿼리만으로 구현할 경우, 동시 트래픽이 많은 환경에서 DB 부하가 심해질 위험.

---

## 2. 개선된 배치 구성

### 2.1 ZeroOffsetItemReader (QueryDSL 활용)

- `OFFSET` 값을 고정(항상 0)시키고, **PK 범위를 조건으로 추가**하여 데이터를 페이징하는 방식.
- 대량 데이터에서도 `OFFSET`에 따른 검색 비용이 사실상 사라져 일정한 조회 성능을 보임.
- **QueryDSL**의 동적 쿼리를 활용해, PK(또는 인덱스 컬럼) 범위를 기반으로 단계별로 데이터를 가져옴.

### 2.2 ExposedCursorItemReader (Kotlin Exposed 활용)

- Kotlin의 **Exposed** 라이브러리를 이용한 Cursor 기반의 ItemReader.
- `JdbcCursorItemReader`와 동일하게 **DB 내부 Cursor**를 사용하지만, Exposed 자체의 DSL 최적화 및 범위 제약을 결합.
- Cursor가 모든 레코드를 한 번에 로딩하지 않도록 **Fetch Size** 등을 적절히 설정하여 **OOM을 예방**하고, 대량 데이터를 빠르게 순회.

### 2.3 Redis 파이프라인을 통한 Aggregation

- 대량 데이터의 집계 처리를 **DB가 아닌 Redis**에 임시 저장 후 파이프라인(Pipeline) 기능을 이용해 대량으로 처리.
- DB 부하를 줄이고, Redis의 빠른 성능을 활용해 **실시간(또는 근실시간) 집계**가 가능.
- Spring Data Redis로는 파이프라인 제어가 어려워, **Redis 파이프라인 명령**을 직접 실행하는 로직으로 구현.

---

## 3. CatalogMarketLowestPriceJobService (배치 예시)

아래 코드는 실제 배치에서 **QueryDslZeroOffsetItemReader** 또는 **ExposedCursorItemReader**를 통해 대량 데이터를 빠르게 읽고,  
**코루틴**(`runBlocking` / `async`)과 **청크 분할**(`chunked`)을 결합하여 병렬로 처리하는 핵심 흐름입니다.

```kotlin
runBlocking {
  // 대상 카테고리별 아이템을 가져올 총 개수와 범위 정의
  val targetCategoryCodes = getTargetMiddleCategoryCodes()

  // 가장 많은 데이터를 먼저 할당하고, 잔여 데이터를 고르게 분산
  val balancedChunks = distributeIntoChunksWithLargestInFirst(targetCategoryCodes, 10)
  logger.info("Chunked Category: $balancedChunks")

  // 병렬(async)로 start() 실행
  balancedChunks.map { async { start(it) } }.forEach { it.await() }
}
```

- **`start()`** 메서드 내에서 실제 데이터를 **ZeroOffsetItemReader**(또는 ExposedCursor 방식)로 읽어와 로직을 처리.
- 대량 데이터를 조금씩 나눠(Chunking) 코루틴으로 병렬 실행하므로, **처리 속도와 확장성**을 동시에 확보.

---

## 4. 네이버 API 연동 및 Key 로테이션 (ClientInfoManager)

대량 크롤링(또는 검색) 시, 네이버 API가 `429`(Too Many Requests) 에러를 발생할 수 있습니다. 이를 해결하기 위해:

1. **여러 개의 네이버 API Key(클라이언트 ID/Secret)**를 Redis에 저장해둠.  
2. `ClientInfoManager`가 현재 사용할 수 있는 **클라이언트 Key 목록**을 Redis에서 확인.  
3. API 호출 시, 에러가 없으면 그대로 진행하며, `429`(쿼리 한도 초과/속도 제한 초과)가 발생하면:  
   - 해당 Key를 **임시 블랙리스트**에 넣거나(`switchToUnusedClientInfo`),  
   - 재시도를 위해 다른 Key로 **즉시 교체**(`setClientInfoFalse`)하여 재호출 시도.

```kotlin
catch (e: FeignClientException) {
  if (e.status() == 429 && e.message != null) {
    if(e.message!!.contains("012")) {
      // 속도 제한
      clientInfoManager.switchToUnusedClientInfo()
    } else if (e.message!!.contains("010")) {
      // 쿼리 한도 초과
      clientInfoManager.setClientInfoFalse()
      clientInfoManager.switchToUnusedClientInfo()
    } else {
      clientInfoManager.switchToUnusedClientInfo()
    }
    // 4번 이하 에러 발생 시 재시도
    if(updatedErrorCount.get() < 4) {
      return searchItemByQuery(query, display, start, sort, filter, exclude, updatedErrorCount)
    }
  }
}
```

- **Key 로테이션** 덕분에 쿼리 한도에 도달했을 경우 **다른 Key**로 즉시 전환해 크롤링을 이어갈 수 있음.
- Redis에는 다음과 같은 키를 저장/조회:
  - `partner:naver:allkey:{날짜}` → 사용할 수 있는 모든 Key
  - `partner:naver:tempkey:{KeyID}` → 잠시 사용하지 않는 Key 임시 저장
  - Key가 완료되거나 블랙리스트로 지정되면 Hash의 값을 `false`로 수정.

---

## 5. 정리

1. **ZeroOffsetItemReader**  
   - Offset 커지는 문제를 PK 조건으로 대체해 항상 빠른 조회 속도 확보.  
   - QueryDSL을 사용하면 **동적 조건**까지 쉽게 처리 가능.

2. **ExposedCursorItemReader**  
   - Cursor 기반으로 **대용량 데이터 효율적 조회** 가능.  
   - **Fetch Size** 조절 등을 통해 메모리 부하(OOM) 위험 감소.

3. **Redis 파이프라인**  
   - 대량 Aggregation 시 DB 부담을 줄이고, 빠른 처리를 위해 Redis로 임시 저장 후 **파이프라인** 실행.

4. **네이버 API Key 로테이션**  
   - 여러 Key를 Redis에서 관리, `429` 발생 시 바로 다른 Key로 전환.  
   - 유연한 재시도로 크롤링 끊김을 최소화.

5. **코루틴 + Chunk 분할**  
   - 대량 데이터를 카테고리, 청크 단위로 나누어 **병렬 실행**.  
   - 처리 시간이 단축되고, 실패 범위가 청크 단위로 격리되어 확장성↑.

---

## 6. 기대 효과

- **페이징 성능**: 5천만 건 이상의 대량 데이터 처리 시에도 Offset 문제 없이 일정한 조회 속도.
- **메모리 사용량**: Cursor 방식 및 페치 사이즈 제어로, **OOM 위험 완화**.
- **API 한계점 극복**: 네이버 검색 API 429 에러 시 Key 자동 스위칭으로 **지속적 크롤링 가능**.
- **DB 부하 분산**: Redis 파이프라인을 통한 Aggregation으로 **DB 로드 감소** 및 **처리 속도 개선**.

결과적으로, **고성능 대량 배치**를 구현하고, **API 연동의 가용성**을 높이는 데 성공했습니다.

> **참고**  
> - ZeroOffsetItemReader, ExposedCursorItemReader 관련 구현체는 각각 `QueryDSL`, `Kotlin Exposed`를 이용해 작성.  
> - Redis 파이프라인은 Spring Data Redis로 직접 파이프라인 명령을 사용하도록 확장.  
> - Key 로테이션 시나리오는 `ClientInfoManager`에서 Redis 해시(Hash) 구조를 통해 활성/비활성 상태를 관리.

